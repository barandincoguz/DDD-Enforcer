"""
Token Usage Tracker

Tracks and reports token usage across all LLM API calls for cost estimation.
Provides detailed statistics for UBMK presentation and research paper.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional
import json


@dataclass
class APICallRecord:
    """Single API call record with token usage."""
    
    timestamp: str
    stage: str  # e.g., "Scout", "Architect", "Specialist", "Violation Detection"
    operation: str  # e.g., "extract_sentences", "identify_contexts"
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int


@dataclass
class TokenUsageStats:
    """Aggregated token usage statistics."""
    
    total_prompt_tokens: int = 0
    total_completion_tokens: int = 0
    total_tokens: int = 0
    total_api_calls: int = 0
    
    # Per-stage breakdown
    stage_stats: Dict[str, Dict[str, int]] = field(default_factory=dict)
    
    # Detailed call log
    call_history: List[APICallRecord] = field(default_factory=list)


class TokenTracker:
    """
    Global token usage tracker for cost estimation and reporting.
    
    Gemini 2.5 Flash Pricing (PAID tier, as of Dec 12, 2025):
    Source: https://ai.google.dev/gemini-api/docs/pricing
    
    - Input: $0.30 per 1M tokens ($0.000000300 per token)
    - Output: $2.50 per 1M tokens ($0.000002500 per token)
    - Cached Input: $0.03 per 1M tokens (implicit caching, charged when enabled)
    
    Token Types Tracked:
    - Prompt Tokens: Input sent to the model (INCLUDES cached tokens in count)
    - Completion Tokens: Output generated by the model (billed at output rate)
    - Cached Tokens: Input from cache (billed at cache rate when used)
    - Total Tokens: Prompt + Completion
    
    Billing Formula:
    - Billable Input Tokens = Prompt Tokens - Cached Tokens
    - Billable Cached Tokens = Cached Tokens (at cache rate)
    - Total Cost = (Billable Input Ã— Input Rate) + (Cached Ã— Cache Rate) + (Output Ã— Output Rate)
    
    Note: Gemini 2.5 Flash includes thinking/reasoning in completion tokens.
    
    Usage:
        tracker = TokenTracker.get_instance()
        tracker.track_api_call(response, stage="Scout", operation="extract")
        report = tracker.get_report()
    """
    
    _instance: Optional['TokenTracker'] = None
    
    def __init__(self):
        self.stats = TokenUsageStats()
        self.session_start = datetime.now().isoformat()
    
    @classmethod
    def get_instance(cls) -> 'TokenTracker':
        """Singleton pattern to ensure single tracker across all modules."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    @classmethod
    def reset(cls):
        """Reset tracker (useful for testing)."""
        cls._instance = None
    
    def track_api_call(
        self, 
        response, 
        stage: str, 
        operation: str
    ) -> None:
        """
        Track token usage from a Gemini API response.
        
        Args:
            response: Gemini API response object with usage_metadata
            stage: Pipeline stage (Scout, Architect, Specialist, Synthesizer, Validator)
            operation: Specific operation name
        """
        # Extract usage metadata from Gemini response
        usage = response.usage_metadata
        
        # Safe extraction with None checks (some responses may have None values)
        prompt_tokens = getattr(usage, 'prompt_token_count', None) or 0
        completion_tokens = getattr(usage, 'candidates_token_count', None) or 0
        
        # Check for cached tokens (context caching feature)
        # IMPORTANT: cached_content_token_count is INCLUDED in prompt_token_count by Gemini
        # We need to subtract it to get billable prompt tokens
        cached_tokens = getattr(usage, 'cached_content_token_count', None) or 0
        
        # Calculate billable tokens (excluding cached)
        billable_prompt_tokens = prompt_tokens - cached_tokens
        billable_total = billable_prompt_tokens + completion_tokens
        
        # Log if there are cached tokens (not billed)
        if cached_tokens > 0:
            print(f"      ðŸ’¾ Cached: {cached_tokens:,} tokens (FREE) | Billable input: {billable_prompt_tokens:,}")
        
        # Create record (only billable tokens)
        record = APICallRecord(
            timestamp=datetime.now().isoformat(),
            stage=stage,
            operation=operation,
            prompt_tokens=billable_prompt_tokens,  # Exclude cached
            completion_tokens=completion_tokens,
            total_tokens=billable_total  # Only billable
        )
        
        # Update aggregated stats (only billable tokens)
        self.stats.total_prompt_tokens += billable_prompt_tokens
        self.stats.total_completion_tokens += completion_tokens
        self.stats.total_tokens += billable_total
        self.stats.total_api_calls += 1
        
        # Update stage-specific stats
        if stage not in self.stats.stage_stats:
            self.stats.stage_stats[stage] = {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0,
                "call_count": 0
            }
        
        self.stats.stage_stats[stage]["prompt_tokens"] += billable_prompt_tokens
        self.stats.stage_stats[stage]["completion_tokens"] += completion_tokens
        self.stats.stage_stats[stage]["total_tokens"] += billable_total
        self.stats.stage_stats[stage]["call_count"] += 1
        
        # Add to call history
        self.stats.call_history.append(record)
    
    #this method calculates the estimated cost based on token usage in Gemini 2.5 Flash pricing
    def calculate_cost(self) -> Dict[str, float]:
        """
        Calculate estimated cost based on Gemini 2.5 Flash pricing.
        
        Pricing (PAID tier - Dec 12, 2025):
        - Input: $0.30 per 1M tokens
        - Output: $2.50 per 1M tokens
        Source: https://ai.google.dev/gemini-api/docs/pricing
        
        Returns:
            Dict with input_cost, output_cost, total_cost in USD
        """
        # Gemini 2.5 Flash pricing (Dec 12, 2025)
        INPUT_PRICE_PER_TOKEN = 0.30 / 1_000_000   # $0.30 per 1M tokens
        OUTPUT_PRICE_PER_TOKEN = 2.50 / 1_000_000  # $2.50 per 1M tokens
        
        input_cost = self.stats.total_prompt_tokens * INPUT_PRICE_PER_TOKEN
        output_cost = self.stats.total_completion_tokens * OUTPUT_PRICE_PER_TOKEN
        total_cost = input_cost + output_cost
        
        return {
            "input_cost": round(input_cost, 6),
            "output_cost": round(output_cost, 6),
            "total_cost": round(total_cost, 6),
            "currency": "USD"
        }
    
    def get_report(self, detailed: bool = False) -> Dict:
        """
        Generate comprehensive token usage report.
        
        Args:
            detailed: Include per-call breakdown
            
        Returns:
            Dict with all statistics and cost estimation
        """
        cost = self.calculate_cost()
        
        report = {
            "session_start": self.session_start,
            "session_end": datetime.now().isoformat(),
            "summary": {
                "total_api_calls": self.stats.total_api_calls,
                "total_prompt_tokens": self.stats.total_prompt_tokens,
                "total_completion_tokens": self.stats.total_completion_tokens,
                "total_tokens": self.stats.total_tokens,
            },
            "cost_estimation": cost,
            "stage_breakdown": {}
        }
        
        # Add stage breakdown
        for stage, stats in self.stats.stage_stats.items():
            stage_input_cost = stats["prompt_tokens"] * (0.30 / 1_000_000)
            stage_output_cost = stats["completion_tokens"] * (2.50 / 1_000_000)
            
            report["stage_breakdown"][stage] = {
                "call_count": stats["call_count"],
                "prompt_tokens": stats["prompt_tokens"],
                "completion_tokens": stats["completion_tokens"],
                "total_tokens": stats["total_tokens"],
                "estimated_cost": round(stage_input_cost + stage_output_cost, 6)
            }
        
        # Add detailed call history if requested
        if detailed:
            report["call_history"] = [
                {
                    "timestamp": call.timestamp,
                    "stage": call.stage,
                    "operation": call.operation,
                    "prompt_tokens": call.prompt_tokens,
                    "completion_tokens": call.completion_tokens,
                    "total_tokens": call.total_tokens
                }
                for call in self.stats.call_history
            ]
        
        return report
    
    def print_summary(self):
        """Print formatted summary to console."""
        cost = self.calculate_cost()
        
        print("\n" + "="*70)
        print("ðŸ“Š TOKEN USAGE & COST REPORT")
        print("="*70)
        print(f"  Total API Calls: {self.stats.total_api_calls}")
        print(f"  Total Tokens: {self.stats.total_tokens:,}")
        print(f"    â†³ Input:  {self.stats.total_prompt_tokens:,} tokens")
        print(f"    â†³ Output: {self.stats.total_completion_tokens:,} tokens")
        print("\n" + "-"*70)
        print("ðŸ’° COST ESTIMATION (Gemini 2.5 Flash)")
        print("-"*70)
        print(f"  Input Cost:  ${cost['input_cost']:.6f}")
        print(f"  Output Cost: ${cost['output_cost']:.6f}")
        print(f"  Total Cost:  ${cost['total_cost']:.6f} USD")
        
        if self.stats.stage_stats:
            print("\n" + "-"*70)
            print("ðŸ“ˆ STAGE BREAKDOWN")
            print("-"*70)
            for stage, stats in self.stats.stage_stats.items():
                stage_cost = (
                    stats["prompt_tokens"] * (0.075 / 1_000_000) +
                    stats["completion_tokens"] * (0.30 / 1_000_000)
                )
                print(f"\n  {stage}:")
                print(f"    Calls: {stats['call_count']}")
                print(f"    Tokens: {stats['total_tokens']:,}")
                print(f"    Cost: ${stage_cost:.6f}")
        
        print("="*70 + "\n")
    
    def export_to_json(self, filepath: str, detailed: bool = True):
        """Export report to JSON file for analysis."""
        report = self.get_report(detailed=detailed)
        with open(filepath, 'w') as f:
            json.dump(report, f, indent=2)
        print(f"ðŸ“„ Token usage report exported to: {filepath}")
